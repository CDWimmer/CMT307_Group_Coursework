{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cropping using AI Object Detection\n",
    "\n",
    "Based on the code found in <a href=\"https://www.pyimagesearch.com/2017/09/11/object-detection-with-deep-learning-and-opencv/\">this article</a>.\n",
    "\n",
    "Using a pre-trained model with OpenCV we'll identify where dogs are within images, in order to obtain cropping coordinates to produce the images without having pre-defined crops provided for us. In this manner we'll be able to take images from outside of the Stanford dogs dataset and have them cropped without human intervention. \n",
    "\n",
    "The model used here was originally trained to detect some 20 objects, one of which is dogs, so we can just disregard any detection that is not a dog, however it does mean this Notebook should be open to future use for other purposes. If a better model exists or is made, one need only swap the model used.\n",
    "\n",
    "The network architecture is a <a href=\"https://arxiv.org/abs/1704.04861\">\"MobileNet\"</a> combined with <a href=\"https://arxiv.org/abs/1512.02325\">SSDs</a> (Single Shot Detectors). Alternatives include R-CNNs and YOLO, however the former is too slow and the latter too inaccurate, so SSDs are a nice balancy between the two. \"MobileNet\" is useful as it is designed for use on smaller devices, e.g. mobile phones, thus it is much smaller than the alternatives in terms of file size - the network used here is barely over 20 MB - and a lot more efficient, at a cost to accurracy, but should still be good enough to identify objects in the vast majority of our images. \n",
    "\n",
    "#### The Model\n",
    "\n",
    "The Caffe model here was trained by Github user <a href=\"https://github.com/chuanqi305/MobileNet-SSD\">chuanqi305</a> using the <a href=\"http://cocodataset.org/\">COCO dataset</a>. \n",
    "\n",
    "More details on the workings of the original code and network can be found in the original article. \n",
    "\n",
    "#### This Implementation\n",
    "\n",
    "We'll be recycling some of the logic and the network from the article. That code was designed for command-line use on a single image at a time, here the detection logic will be refitted to work automatically with all of the images from our dataset, organsing the output similarly to the previous dataset processor. \n",
    "\n",
    "It requires you have the images and Matlab list files from the <a href=\"http://vision.stanford.edu/aditya86/ImageNetDogs/\">Stanford dog dataset</a> unpacked into folders of `images`, `lists`, adjacent to this Notebook file. Note this does _not_ require the annotation files. Simply unpack the folder from the provided .tar files into the same directory as ths notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating missing directories... Done\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# for displaying images \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "from scipy import io\n",
    "from os import path, mkdir, rename\n",
    "from random import random, seed, choices\n",
    "from IPython.display import display, clear_output\n",
    "import xmltodict\n",
    "\n",
    "########## Customisation ##########\n",
    "# fractions (sum=1):\n",
    "frac_train = 0.8\n",
    "frac_dev = 0.1\n",
    "frac_test = 0.1\n",
    "\n",
    "# Our output folder:\n",
    "image_path_sorted = \"images_sorted_auto\"\n",
    "\n",
    "# minimum percent confidence (between 0 and 1) in a detection the network requires \n",
    "# to consider that detection as being correct:\n",
    "confidence_requirement = 0.4\n",
    "###################################\n",
    "\n",
    "image_path_train = path.join(image_path_sorted, \"train\")\n",
    "image_path_dev = path.join(image_path_sorted, \"dev\")\n",
    "image_path_test = path.join(image_path_sorted, \"test\")\n",
    "if not path.exists(image_path_sorted):\n",
    "    print(\"Creating missing directories... \", end='', flush=True)\n",
    "    mkdir(image_path_sorted)\n",
    "    mkdir(image_path_train)\n",
    "    mkdir(image_path_dev)\n",
    "    mkdir(image_path_test)\n",
    "    print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pre-trained network files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model... Done!\n"
     ]
    }
   ],
   "source": [
    "########### customisation #############\n",
    "network_f_folder = \"detectionNetwork\" # directory the network files are\n",
    "model = \"MobileNetSSD_deploy.caffemodel\" # caffee model file\n",
    "prototxt = \"MobileNetSSD_deploy.prototxt.txt\" # model prototxt\n",
    "#######################################\n",
    "\n",
    "# classes the network has been trained to detect\n",
    "CLASSES = [\"background\", \"aeroplane\", \"bicycle\", \"bird\", \"boat\",\n",
    "    \"bottle\", \"bus\", \"car\", \"cat\", \"chair\", \"cow\", \"diningtable\",\n",
    "    \"dog\", \"horse\", \"motorbike\", \"person\", \"pottedplant\", \"sheep\",\n",
    "    \"sofa\", \"train\", \"tvmonitor\"]\n",
    "#COLORS = np.random.uniform(0, 255, size=(len(CLASSES), 3))\n",
    "interested = [12] # CLASSES[12]=\"dog\"\n",
    "\n",
    "print(\"loading model... \", end=\"\", flush=True)\n",
    "model_path = path.join(network_f_folder, model)\n",
    "prototxt_path = path.join(network_f_folder, prototxt)\n",
    "net = cv2.dnn.readNetFromCaffe(prototxt_path, model_path)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# auto split function\n",
    "pop = [image_path_train, image_path_dev, image_path_test]\n",
    "prob = [frac_train, frac_dev, frac_test]\n",
    "def split_loc():\n",
    "    \"\"\"Randomly chooses which category to put the image in. Returns directory path.\"\"\"\n",
    "    res = choices(population=pop, weights=prob, k=1)\n",
    "    return res[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load list of images. \n",
    "This section could be replaced with different code for a different set of labelled images. Thus functioning for any set of images. So long as `file_list` is defined as a list of list-like objects, where each object within `file-list` has index 0 as the path of a file relative to `image_path`, and index 1 as the object Y-label. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load our list of original Stanford images and labels\n",
    "image_path = \"images\"\n",
    "lists_path = \"lists\"\n",
    "\n",
    "\n",
    "files_mat = io.loadmat(path.join(lists_path, \"file_list.mat\"))\n",
    "file_list = [[item[0][0], item[0][0].split('/')[0]] for item in files_mat[\"file_list\"]]\n",
    "#print(file_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Progress tracker setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Progress tracking\n",
    "######## Customisation #########\n",
    "prog_track = True # toggle tracker\n",
    "freq_track = 100 # how often to update\n",
    "############################\n",
    "\n",
    "\n",
    "processed = 0\n",
    "state = freq_track\n",
    "total_images = len(file_list)\n",
    "\n",
    "errors = 0\n",
    "no_det = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Processing\n",
    "Here we finally perform the image sorting,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 15500 | 75.316%\n",
      "Non-detections: 2371 | Errors: 0\n"
     ]
    }
   ],
   "source": [
    "for file in file_list:\n",
    "    # progress tracking\n",
    "    if prog_track == True:\n",
    "        interests_detected = 0\n",
    "        if state >= freq_track:\n",
    "            clear_output(wait=True)\n",
    "            state = 0\n",
    "            print(f\"Done {processed} | {100*(processed/total_images):.3f}%\")\n",
    "            print(f\"Non-detections: {no_det} | Errors: {errors}\")\n",
    "        processed+=1\n",
    "        state +=1\n",
    "        \n",
    "    sub_folder = file[1]\n",
    "    image = cv2.imread(path.join(image_path, file[0]))\n",
    "    (h, w) = image.shape[:2]\n",
    "    blob = cv2.dnn.blobFromImage(cv2.resize(image, (300, 300)), 0.007843, (300, 300), 127.5)\n",
    "    net.setInput(blob)\n",
    "    detections = net.forward()\n",
    "    for i in np.arange(0, detections.shape[2]):\n",
    "        # extract the confidence (i.e., probability) associated with the\n",
    "        # prediction\n",
    "        confidence = detections[0, 0, i, 2]\n",
    "        \n",
    "        # choose where we're putting it (train/test/dev)\n",
    "        # and make a class folder \n",
    "        loc = path.join(split_loc(), sub_folder)\n",
    "        if not path.exists(loc):\n",
    "            mkdir(loc)\n",
    "        idx = int(detections[0, 0, i, 1])\n",
    "        # filter out weak detections by ensuring the `confidence` is\n",
    "        # greater than the minimum confidence\n",
    "        if confidence > confidence_requirement:\n",
    "            \n",
    "            # extract the index of the class label from the `detections`,\n",
    "            # check if its a dog, \n",
    "            # then compute the (x, y)-coordinates of the bounding box for\n",
    "            # the object, then crop it out, then save it to a file. \n",
    "            idx = int(detections[0, 0, i, 1])\n",
    "            if idx not in interested:\n",
    "                continue # skip anything not of interest\n",
    "            else:\n",
    "                interests_detected += 1\n",
    "                box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "                (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "                if startX < 0: startX = 0\n",
    "                #if startX > w: startX = w\n",
    "                if startY < 0: startY = 0\n",
    "                #if startY > h: startY = h\n",
    "                    \n",
    "                    \n",
    "                img_crop = image[startY:endY, startX:endX]\n",
    "                #print(f\"detection in {file[0]}\")\n",
    "                #print(startY, endY, startX, endX)\n",
    "                \n",
    "                final_path = path.join(loc, f\"{file[0].split('/')[1]}_{i}_c{confidence*100:.2f}.jpg\")\n",
    "                #print(final_path)\n",
    "                try:\n",
    "                    cv2.imwrite(final_path, img_crop)\n",
    "                    # Note that pyplot and OpenCV use differnt image formats so the colours look stragne\n",
    "                    # when displayed by plt.imshow()\n",
    "                    #plt.imshow(img_crop)\n",
    "                    #plt.show()\n",
    "                except Exception as e:\n",
    "                    print(f\"Encountered an error, skipping.\\n{e}\")\n",
    "                    errors += 1\n",
    "                                       \n",
    "    # progress tracking   \n",
    "    if prog_track == True and interests_detected == 0:\n",
    "        no_det += 1\n",
    "\n",
    "if prog_track == True:\n",
    "    clear_output(wait=True)\n",
    "    print(f\"Done {processed} | {100*(processed/total_images):.3f}%\")\n",
    "    print(f\"Non-detections: {no_det} | Errors: {errors}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Current issues</u>: \n",
    "- Naming files is a bit of a mess and the whole thing could be made more sensible in this regard. `path.join(loc, f\"{file[0].split('/')[1]}` where `loc` contains the first half of `file[0]` is really stupid.\n",
    "- I've since discovered the `split-folders` Python package which would deal with sorting the images into folders automatically without having to write that code myself, however due to only just finding out it exists at such late notice, I have not implemented it here. \n",
    "- The network we're using here is of course not designed for *just* dogs but 20 object classes in total. It would likely see an improvement were we to train a new model from scratch for this purpose, but as this is a proof-of-concept, the existing model is sufficient to show it has promise of being highly effective. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
