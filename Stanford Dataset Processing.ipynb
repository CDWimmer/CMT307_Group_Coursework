{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "from os import path, mkdir, rename\n",
    "try:\n",
    "    import xmltodict\n",
    "except ImportError:\n",
    "    print(\"Installing a module to convert XML into Python dictionaries, hold on...\")\n",
    "    !conda install --yes --prefix {sys.prefix} xmltodict  # I really hope you're running conda\n",
    "    import xmltodict\n",
    "\n",
    "from IPython.display import display, clear_output\n",
    "from PIL import Image  # for working with images\n",
    "from random import random, seed, choices\n",
    "# Stanford files:\n",
    "annotation_path = \"annotations\"\n",
    "image_path_original = \"images\"\n",
    "lists_path = \"lists\"\n",
    "\n",
    "# Our files:\n",
    "image_path_sorted = \"images_sorted\"\n",
    "image_path_train = path.join(image_path_sorted, \"train\")\n",
    "image_path_dev = path.join(image_path_sorted, \"dev\")\n",
    "image_path_test = path.join(image_path_sorted, \"test\")\n",
    "\n",
    "if not path.exists(image_path_sorted):\n",
    "    print(\"Creating missing directories... \", end='', flush=True)\n",
    "    mkdir(image_path_sorted)\n",
    "    mkdir(image_path_train)\n",
    "    mkdir(image_path_dev)\n",
    "    mkdir(image_path_test)\n",
    "    print(\"Done\")\n",
    "\n",
    "\n",
    "# fractions (sum=1):\n",
    "frac_train = 0.8\n",
    "frac_dev = 0.1\n",
    "frac_test = 0.1\n",
    "\n",
    "    \n",
    "file_list = io.loadmat(path.join(lists_path, \"file_list.mat\"))\n",
    "train_list = io.loadmat(path.join(lists_path, \"train_list.mat\"))\n",
    "test_list = io.loadmat(path.join(lists_path, \"test_list.mat\"))\n",
    "\n",
    "# Random seed - leave unchanged for consistency between runs\n",
    "seed(343)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Translation Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Noting that the `file_list.mat` file contains numerical labels, meanwhile the XML metadata/annotation files contain written text labels, we'll build a \"translation table\" of text labels $\\rightarrow$ numerical labels and vice versa, which will come in useful later.\n",
    "\n",
    "Critical assumption: given 1 label is given to all files, files with multiple dogs must all the same breed. \n",
    "\n",
    "We'll also tally the total number of images for convenience later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Breed</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Chihuahua</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Japanese_spaniel</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Maltese_dog</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Pekinese</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Shih-Tzu</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>115</td>\n",
       "      <td>standard_poodle</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>116</td>\n",
       "      <td>Mexican_hairless</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>117</td>\n",
       "      <td>dingo</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>118</td>\n",
       "      <td>dhole</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>119</td>\n",
       "      <td>African_hunting_dog</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Breed  Label\n",
       "0              Chihuahua      1\n",
       "1       Japanese_spaniel      2\n",
       "2            Maltese_dog      3\n",
       "3               Pekinese      4\n",
       "4               Shih-Tzu      5\n",
       "..                   ...    ...\n",
       "115      standard_poodle    116\n",
       "116     Mexican_hairless    117\n",
       "117                dingo    118\n",
       "118                dhole    119\n",
       "119  African_hunting_dog    120\n",
       "\n",
       "[120 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "translation_table_txt2num = dict()\n",
    "total_images = 0\n",
    "for annotation, label in zip(file_list[\"annotation_list\"], file_list[\"labels\"]):\n",
    "    total_images += 1\n",
    "    with open(path.join(annotation_path, annotation[0][0]), 'rb') as f:\n",
    "        meta_dict = xmltodict.parse(f.read())[\"annotation\"]\n",
    "        if isinstance(meta_dict[\"object\"], list):\n",
    "            translation_table_txt2num[meta_dict[\"object\"][0][\"name\"]] = label[0]\n",
    "        else:\n",
    "            translation_table_txt2num[meta_dict[\"object\"][\"name\"]] = label[0]\n",
    "df = pd.DataFrame.from_dict(translation_table_txt2num, orient='index', columns=[\"Count\"]).reset_index()\n",
    "df.columns = [\"Breed\", \"Label\"]\n",
    "display(df)\n",
    "df.to_csv(\"label_translation_table_txt2num.csv\")\n",
    "\n",
    "translation_table_num2txt = {v: k for k, v in translation_table_txt2num.items()}  # inverted trans table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Splits and Bounding Boxes \n",
    "\n",
    "Although the Stanford dataset did come ready with test/train splits, they were around 58:42, far from the 80:10:10 decided on by the group members. As such I'll use random numbers with a constant seed to generate my own splits in a reproducable manner. \n",
    "\n",
    "- Problem: I currently pull file names from the XML data however randomly some simply have \"%s\" as a file name. e.g. English Foxhound `n02089973_382`\n",
    "\n",
    "Solution: ?\n",
    "\n",
    "\n",
    "- ~~Problem~~: For whatever reason, despite all images *supposedly* being JPGs with a depth of 3, I happened across an error where PIL reported an image had an Alpha channel (RGBA) which cannot be saved as a JPEG/JPG.\n",
    "\n",
    "Solution: `im.mode` and `im.convert`, also saving as PNG to avoid lossy compression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bbox_cut(im, bndbox):\n",
    "    \"\"\"Takes a PIL image and crops out to the supplied coordinates. Returns cropped image object.\"\"\"\n",
    "    # As Image.crop works from the top left corner we need to do our y coordinates upsidedown. \n",
    "    box = (int(bndbox[\"xmin\"]), int(bndbox[\"ymin\"]), int(bndbox[\"xmax\"]), int(bndbox[\"ymax\"]))\n",
    "    im_crop = im.crop(box)\n",
    "    return im_crop\n",
    "\n",
    "pop = [image_path_train, image_path_dev, image_path_test]\n",
    "prob = [frac_train, frac_dev, frac_test]\n",
    "def split_loc():\n",
    "    \"\"\"Randomly chooses which category to put the image in. Returns directory path.\"\"\"\n",
    "    res = choices(population=pop, weights=prob, k=1)\n",
    "    return res[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Switch to True to see the resulting images as they're processed. \n",
    "visualise = False\n",
    "\n",
    "# Print occasional % updates\n",
    "prog_track = True\n",
    "processed = 0\n",
    "freq_track = 100\n",
    "state = freq_track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 20500 | 99.61127%\n"
     ]
    }
   ],
   "source": [
    "for image, annotation, label in zip(file_list[\"file_list\"], file_list[\"annotation_list\"], file_list[\"labels\"]):\n",
    "    if visualise:\n",
    "        clear_output(wait=True)\n",
    "    if prog_track == True:\n",
    "        if state >= freq_track:\n",
    "            clear_output(wait=True)\n",
    "            state = 0\n",
    "            print(f\"Done {processed} | {100*(processed/total_images):.3f}%\")\n",
    "        processed+=1\n",
    "        state +=1\n",
    "    # load image with PIL:\n",
    "    im = Image.open(path.join(image_path_original, image[0][0]))\n",
    "    # Ensure image is RGB (e.g. not RGBA or whatever...)\n",
    "    if im.mode is not \"RGB\":\n",
    "        im = im.convert(\"RGB\")\n",
    "    if visualise:\n",
    "        display(im)\n",
    "    #open annotation file and get bounding box data:\n",
    "    with open(path.join(annotation_path, annotation[0][0]), 'rb') as f:\n",
    "        meta_dict = xmltodict.parse(f.read())[\"annotation\"]\n",
    "        # Check if there's multiple dogs listed to be in the image:\n",
    "        if isinstance(meta_dict[\"object\"], list):\n",
    "            # Where there's more than one:\n",
    "            for i, obj_dict in enumerate(meta_dict[\"object\"]): \n",
    "                # get our cropped image and save it as `filename-cropnumber-label.png`\n",
    "                im_cut = bbox_cut(im, obj_dict[\"bndbox\"])\n",
    "                if visualise:\n",
    "                    display(im_cut)\n",
    "                im_cut.save(path.join(split_loc(), f\"{meta_dict['filename']}-{i}-{translation_table_txt2num[obj_dict['name']]}.png\"))\n",
    "                \n",
    "        else:  # where there's only one dog:\n",
    "            obj_dict = meta_dict[\"object\"]\n",
    "            im_cut = bbox_cut(im, obj_dict[\"bndbox\"])\n",
    "            if visualise:\n",
    "                display(im_cut)\n",
    "            im_cut.save(path.join(split_loc(), f\"{meta_dict['filename']}-{0}-{translation_table_txt2num[obj_dict['name']]}.png\"))\n",
    "\n",
    "if prog_track == True:\n",
    "    clear_output(wait=True)\n",
    "    print(f\"Done {processed} | {100*(processed/total_images):.3f}%\")                                  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO:\n",
    "- ~~cut out bounding boxes~~\n",
    "- ~~Split into train, dev, and test sets~~\n",
    "- merge in the renaming scheme from other group members, or propose a new one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
